{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDS Final Project - Cemplate\n",
    "Ima drop some template here for easy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# surpess warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "So here, we can prepare the datasets to test out the models. We can use several of them during our analysis, and see how the models perform on different datasets. If there is no variation in the performance, then we may remove all but one before the final submission. Or use it as an evidence of robustness. \n",
    "\n",
    "I am intentionally not changing the columns for now, so you can see the data as it is. Later on, we will have one column of **text** and one column of **label**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffpost.com/entry/covid-boosters-...</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>Carla K. Johnson, AP</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.huffpost.com/entry/covid-boosters-...   \n",
       "\n",
       "                                            headline   category  \\\n",
       "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
       "\n",
       "                                   short_description               authors  \\\n",
       "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
       "\n",
       "        date  \n",
       "0 2022-09-23  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data from Huffington Post, no null values\n",
    "huff_post = pd.read_json('data/huff_post.json', lines=True)\n",
    "huff_post.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>news</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.larepublica.co/redirect/post/3201905</td>\n",
       "      <td>Durante el foro La banca articulador empresari...</td>\n",
       "      <td>Otra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                url  \\\n",
       "0  https://www.larepublica.co/redirect/post/3201905   \n",
       "\n",
       "                                                news  Type  \n",
       "0  Durante el foro La banca articulador empresari...  Otra  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data from Bancolombia, no null values\n",
    "bancolombia = pd.read_csv('data/bancolombia.csv')\n",
    "bancolombia.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we set up the classifiers we are going to use. Since SKLearn has a constant interface, we can just use a list of classifiers and iterate over them. For example, they all have a `fit` method, and a `predict` method. So we can just call them in a loop, and get the results. That is what I've seen in the other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will import Naive Bayes, softmax classifier, and svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=1, C=0.1),\n",
    "    LogisticRegression(penalty='l2', C=0.1),\n",
    "    SVC()\n",
    "]\n",
    "\n",
    "classifier_names = ['Naive Bayes', 'Softmax ElasticNet', 'Softmax L2', 'SVM']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Predict\n",
    "\n",
    "So here we fit the model, and predict the results. I am just printint the accuracy for the training set, and the test set. But we can also print other metrics. Also SKLearn has a `classification_report` function that can be used to print the precision, recall, and f1-score for each class, just writing this down so I don't forget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will import CountVectorizer to vectorize our text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# we will import train_test_split to split our data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((973, 7661), (244, 7661), (973,), (244,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load stopwords\n",
    "with open('stopwords/spanish', 'rb') as f:\n",
    "    spanish_stopwords = pickle.load(f)\n",
    "    \n",
    "vectorizer = CountVectorizer(min_df=5, stop_words=spanish_stopwords)\n",
    "X = vectorizer.fit_transform(bancolombia['news'])\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, bancolombia['Type'], test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:\t\t Naive Bayes\n",
      "Training time:\t\t 0.013 seconds\n",
      "Training data accuracy:\t 0.952\n",
      "Test data accuracy:\t 0.865\n",
      "\n",
      "Classifier:\t\t Softmax ElasticNet\n",
      "Training time:\t\t 1.692 seconds\n",
      "Training data accuracy:\t 0.899\n",
      "Test data accuracy:\t 0.844\n",
      "\n",
      "Classifier:\t\t Softmax L2\n",
      "Training time:\t\t 1.147 seconds\n",
      "Training data accuracy:\t 0.997\n",
      "Test data accuracy:\t 0.844\n",
      "\n",
      "Classifier:\t\t SVM\n",
      "Training time:\t\t 3.175 seconds\n",
      "Training data accuracy:\t 0.955\n",
      "Test data accuracy:\t 0.799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and test each classifier\n",
    "for i, clf in enumerate(classifiers):\n",
    "    # start timer\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print(f'Classifier:\\t\\t {classifier_names[i]}')\n",
    "    print(f'Training time:\\t\\t {end - start:.3f} seconds')\n",
    "    print(f'Training data accuracy:\\t {clf.score(X_train, y_train):.3f}')\n",
    "    print(f'Test data accuracy:\\t {clf.score(X_test, y_test):.3f}')\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Here we can look deeper into the models. As an example, below I am printing the most important words (that have the highest conditonal probability given a class) for the Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbc = MultinomialNB()\n",
    "nbc.fit(X_train, y_train)\n",
    "phi = nbc.feature_log_prob_\n",
    "phi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most informative features for each class for Naive Bayes\n",
      "\n",
      "Alianzas:\t parte, presidente, año, mercado, empresas, 000, país, millones, alianza, colombia\n",
      "Innovacion:\t tecnología, forma, través, innovación, digital, empresas, banco, datos, clientes, bbva\n",
      "Macroeconomia:\t aumento, economía, alimentos, 2022, mayor, crecimiento, bbva, año, precios, inflación\n",
      "Otra:\t\t 000, crédito, financiera, entidad, año, clientes, colombia, millones, banco, bbva\n",
      "Regulaciones:\t año, si, servicios, gobierno, mercado, país, dijo, empresas, colombia, regulación\n",
      "Reputacion:\t mejor, puesto, colombia, país, 10, millones, posición, sector, reputación, empresas\n",
      "Sostenibilidad:\t puede, millones, cada, además, cambio, agua, sostenibilidad, sostenible, energía, bbva\n"
     ]
    }
   ],
   "source": [
    "print('Most informative features for each class for Naive Bayes', end='\\n\\n')\n",
    "for i, cls in enumerate(nbc.classes_):\n",
    "    if cls == 'Otra':\n",
    "        print(f'{cls}:\\t\\t', end=' ')\n",
    "    else:\n",
    "        print(f'{cls}:\\t', end=' ')\n",
    "    print(', '.join([vectorizer.get_feature_names()[j] for j in phi[i].argsort()[-10:]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "782117f08ed859aa13a701b87eaecaa1d2e6c59a6ebb52301f0d1b251c4747e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
